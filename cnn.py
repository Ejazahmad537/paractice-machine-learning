# -*- coding: utf-8 -*-
"""CNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qVCafnl4US3_nfGOSjmwzNdOkdcFYLB6
"""

#import requird packegs

import numpy as np
import pandas as pd
import keras
import tensorflow as tf

#checking avalible devices
import tensorflow as tf
from tensorflow.python.client import device_lib
print(device_lib.list_local_devices())

#Loding Dataset
from keras.datasets import mnist
(X_train, Y_train), (X_test, Y_test) = mnist.load_data()

import matplotlib.pyplot as plt
#Number of digits to display
n = 10

#create a figure to display the image
plt.figure(figsize=(20, 4))

#Loop throug the first 'n' image
for i in range(n):
  #create a subplot withen the figure
  ax = plt.subplot(2, n, i+1)

  #display the original image
  plt.imshow(X_test[i].reshape(28,28))

  #set colormap to grayscale
  plt.gray

  #Hide x_axis and y_axis lables and tackes
  ax.get_xaxis().set_visible(False)
  ax.get_yaxis().set_visible(False)


#show the figure with the image
plt.show()

#close the figure
plt.close()

"""#Displaying the shapes of datasets"""

print('x_train shape :', X_train.shape)
print('y_train shape :', Y_train.shape)
print('x_test shape :' , X_test.shape)
print('y_test shape :' , Y_test.shape)

"""#Reshping the data"""

#Reshaping the data in 'channel last' formate for consumption of Tensorflow backend
X_train = X_train.reshape(X_train.shape[0],28,28,1)
X_test = X_test.reshape(X_test.shape[0], 28,28,1)

"""#Min Mix Scalling"""

X_train = X_train.astype('float32')
X_test = X_test.astype('float32')
X_train /= 255
X_test /= 255

"""#one hot encoding"""

from keras.utils import to_categorical
Y_train = to_categorical(Y_train, num_classes= 10)
Y_test = to_categorical(Y_test, num_classes= 10)

#seeng updates shapes
print('x_train shape', X_train.shape)
print('y_train shape', X_train.shape)
print('x_test shape', X_test.shape)
print('y_test shape', X_test.shape)

"""#Bulding the CNN"""

!pip install --upgrade tensorflow keras

from keras.models import Sequential
from keras.layers import Dense, Flatten
from tensorflow.keras.layers import Conv2D

#image_rows , image_colonm  channels = 28,28 , 1 # 1 for grayscale images and 3 for rgb images
#filteers = [6, 80 ,32, 120]
#classes = 10
imag_rws, img_cols, channels = 28,28 , 1 # 1 for grayscale images and 3 for rgb images

#define the number of filters of each layers of the CNN
filters = [6, 80 ,32, 120]

#define the number of classification
classes = 10

"""#Creating Model"""

!pip install --upgrade tensorflow

model.compile(
    loss='categorical_crossentropy',  # Named argument
    optimizer='sgd',                 # Named argument
    metrics=['accuracy']             # Note: 'metrics' expects a list!
)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D

# Define your parameters
img_rows, img_cols = 28, 28  # Example: MNIST image dimensions
channels = 1                  # 1 for grayscale, 3 for RGB
filters = [32, 64, 128, 256]  # Number of filters for each Conv2D layer
classes = 10                   # Number of output classes

# Create the model
model = Sequential()

# First Conv Block
model.add(Conv2D(filters[0], (3, 3), padding='same',
                activation='relu', input_shape=(img_rows, img_cols, channels)))
model.add(MaxPooling2D(pool_size=(2, 2)))

# Second Conv Block
model.add(Conv2D(filters[1], (3, 3), padding='same', activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

# Third Conv Block
model.add(Conv2D(filters[2], (3, 3), padding='same', activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

# Fourth Conv Block
model.add(Conv2D(filters[3], (3, 3), padding='same', activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

# Fully Connected Layers
model.add(Flatten()) #Example:

#Input to last Conv layer: (None, 7, 7, 64) (batch, height, width, channels)

#After Flatten: (None, 3136) (where 3136 = 7 × 7 × 64)

model.add(Dense(64, activation='relu'))
model.add(Dense(classes, activation='softmax'))

# Compile the model
model.compile(loss='categorical_crossentropy',
              optimizer='sgd',
              metrics=['accuracy'])

# Print model summary
model.summary()

"""#Training the CNN"""

model.fit(X_train, Y_train, validation_split= 0.2, epochs= 15, batch_size= 64, verbose= 1)

"""#Testing the Model"""

# Import necessary libraries
from sklearn.metrics import accuracy_score
import numpy as np

# --- If you don't have real data, create synthetic data ---
if 'X_test' not in locals() or 'y_test' not in locals():
    print("Creating synthetic data for demonstration...")
    np.random.seed(42)
    X_test = np.random.rand(100, 10)  # 100 samples, 10 features
    y_test = np.random.randint(0, 2, 100)  # Binary labels (0 or 1)

    # Create and train a simple model (for demo only - normally use real training data)
    from sklearn.linear_model import LogisticRegression
    model = LogisticRegression()
    model.fit(X_test, y_test)  # In practice, use X_train/y_train here

# Get predicted probabilities (for class 1)
y_pred_probs = model.predict_proba(X_test)[:, 1]

# Convert probabilities to binary predictions (0 or 1)
y_pred = np.where(y_pred_probs > 0.5, 1, 0)

# Calculate and display accuracy
test_accuracy = accuracy_score(y_test, y_pred)
print(f'\nTest accuracy: {test_accuracy:.2%}')  # Shows as percentage with 2 decimals

import numpy as np
import matplotlib.pyplot as plt

# 1. FIRST DEFINE YOUR VALIDATION DATA
# Example using MNIST data format (28x28 images)
# Replace this with your actual data loading code
if 'X_valid' not in locals():
    print("Creating dummy validation data...")
    X_valid = np.random.rand(10, 28, 28, 1)  # 10 sample MNIST-like images
    y_pred_probs_valid = np.random.rand(10, 10)  # 10 class probabilities

# 2. SET UP THE DISPLAY
n = len(X_valid)  # Number of validation samples
plt.figure(figsize=(20, 4))

# 3. DISPLAY EACH IMAGE AND PREDICTION
for i in range(n):
    # Display original image
    ax = plt.subplot(2, n, i+1)
    plt.imshow(X_valid[i].reshape(28, 28), cmap='gray')  # Reshape and show as grayscale
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_xaxis().set_visible(False)

    # Display predicted digit
    predicted_digit = np.argmax(y_pred_probs_valid[i])
    ax = plt.subplot(2, n, i+1+n)
    plt.text(0.5, 0.5, str(predicted_digit),
             fontsize=20,  # Increased font size for better visibility
             ha='center',
             va='center')
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

plt.tight_layout()  # Prevent label overlaps
plt.show()